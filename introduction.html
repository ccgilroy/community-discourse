
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Introduction &#8212; Community Discourse with Word Embeddings</title>
    
  <link rel="stylesheet" href="_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Word similarity" href="word-similarity.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  
  <h1 class="site-logo" id="site-title">Community Discourse with Word Embeddings</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1 current active">
  <a class="reference internal" href="#">
   Introduction
  </a>
 </li>
</ul>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="word-similarity.html">
   Word similarity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="wmdistance.html">
   Document similarity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="binary-axes.html">
   Binary axes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="historical-change.html">
   Historical change
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="discussion.html">
   Discussion
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/introduction.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/ccgilroy/community-discourse"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h1>
<p>This project analyzes general public discourse in English about “community” using the computational text analysis method of <em>word embeddings</em>.</p>
<p>Community is a concept that social actors invoke in heterogeneous ways to a variety of ends. I find those varied uses interesting, and I suspect there’s some systematic structure underlying the variation. When protestors adopt “invest in community” as a core demand of their movement, what they mean is somehow fundamentally different from when a company adopts “give people the power to build community” as its mission The intrinsic flexibility and ambiguity of the word may be part of its power, but what’s different, and what’s common, is part of the puzzle.</p>
<p>At their core, all text-as-data approaches translate language into numbers. Word embeddings are a dense representation of text in a multidimensional vector space; that’s the key difference from the document-term matrices that feed into more familiar approaches like topic modeling. That dense vector representation enables different kinds of analyses – not necessarily better, just different.</p>
<p>NLP researchers have used embeddings for linguistic tasks like analogy and similarity for several years, and they’ve begun to develop more complex approaches like contextual and sentence-level embeddings. Meanwhile, social scientists are still sorting out how ordinary word-level embeddings might be useful to us. In sociology, cultural sociologists have led the way. Kozlowski et al (2019) published “The Geometry of Culture” in ASR, analyzing historical change in different dimensions of social class. In a series of methodological papers, Stoltz and Taylor (2019, 2020) have translated and extended an approach for measuring document similarities to measure concept engagement in texts. Arseniev-Koehler and Foster (2020) have developed a theory of bias and cultural learning. At the same time, political scientists (Rheault and Cochrane 2020, Rodriguez and Spirling 2020) have begun to apply embeddings models to legislative proceedings and political speeches.</p>
<p>These pages are a <em>prototype</em> for ongoing work. My intention is to develop this work into the first empirical chapter of my dissertation, and eventually into a publishable paper. My preliminary goal here isn’t to answer any particular empirical research question about community; it’s to implement and understand methods so I can determine which ones are most relevant for my substantive research interests. To that end, I’ve read the methods and code for some of the papers I described above, assessed their commonalities and differences, and implemented examples for what I see as common techniques in this new field.</p>
<p>In the following pages, I’ve grouped those techniques into <strong>four notebooks</strong> based on the distinct aims they accomplish:</p>
<ul class="simple">
<li><p><strong>Word similarity:</strong> The most straighforward application of embeddings is to measure the similarity between individual words. I compare and contrast two pretrained, widely-available sets of embeddings in terms of which words they highlight as most similar to the word “community”, and visualize those nearest neighbors to “community” with PCA. Despite the differences I uncover, the two sets of embeddings I examine ultimately show a moderately strong correlation in terms of how similar other words are to the word “community.”</p></li>
<li><p><strong>Document similarity:</strong> Word-level embeddings can be used for comparisons beyond individual words, at the scale of entire texts. An approach for using word embeddings to produce a document-level measure of similarity is Word Mover’s Distance, or the related Concept Mover’s Distance. I show that this measure has reasonable face validity when ranking Wikipedia articles in terms of how related they are to the concept of “community.”</p></li>
<li><p><strong>Binary axes:</strong> Word embeddings can be algebraically composed to represent binary concepts. I construct one binary dimension that differentiates “community” from the closely-related word “society”, and another that distinguishes words that are more “local” from those that are more “global”. I choose words similar to both “community” and “society” to evaluate against these dimensions, and I generally find that the results are intuitively reasonable.</p></li>
<li><p><strong>Historical change:</strong> Comparing sets of historical embeddings is a way to examine how much a word’s meaning shifts or remains stable over time. I show that “community” has been relatively but not completely stable over the 20th century. Some other words have grown more similar to community as their own meanings have shifted. I use the notion of “gay community” as an illustrative example.</p></li>
</ul>
<p>Of course, these separate techniques can be, and have been, combined in various ways. I don’t doubt that social scientists will continue to push the applications of word embeddings even further, and to translate, interrogate, and import the innovations coming out of NLP research.</p>
<div class="toctree-wrapper compound">
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='right-next' id="next-link" href="word-similarity.html" title="next page">Word similarity</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Connor Gilroy<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>